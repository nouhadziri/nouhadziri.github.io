---
layout: about
title: Nouha Dziri
permalink: /
subtitle: 

profile:
  align: right
  image: prof_pic.jpg # find it in > assets > img
  image_circular: false # crops the image to make it circular

news: true  # includes a list of news items
latest_posts: false  # includes a list of the newest posts
selected_papers: false # includes a list of papers marked as "selected={true}"
social: true  # includes social icons at the bottom of the page
---

I'm a research scientist at [Allen Institute for AI (AI2)](https://allenai.org/).
**I co-led the safety and post-training effort at Ai2** to build [(OLMo)](https://allenai.org/olmo): a highly capable and truly open LLM to advance AI.

Prior to this, I was a postdoc with [Yejin Choi](https://yejinc.github.io/). My research focuses on NLP and ML, with a particular emphasis on LLMs. I work on:

- **Understanding Limits of LLMs**: I study how and why LLMs succeed or fail to generalize on OOD reasoning tasks. Is it true algorithmic understanding or pattern matching? Check out my works ([Faith and Fate](https://arxiv.org/pdf/2305.18654); NeurIPS 2023), ([Generative AI Paradox](https://openreview.net/pdf?id=CF8H8MS5P8); ICLR 2024), ([OMEGA](https://arxiv.org/pdf/2506.18880); NeurIPS 2025)
- **Advancing Reasoning Capabilities in LLMs**: I develop training methods and datasets to systematically advance reasoning in mathematical and code domains. Check out the [RL Grokking Recipe](https://arxiv.org/pdf/2509.21016) and my contributions to post-training large-scale efforts ([Tulu 3](https://arxiv.org/pdf/2411.15124) & [OLMo2](https://arxiv.org/pdf/2501.00656); COLM 2025).
- **Ensuring LLMs Safety**: I ensure that safety advances in step with model capabilities. I led the creation of a safety suite for OLMo, including an automated red-teaming framework ([Wildteaming](https://openreview.net/pdf?id=n5R6TvBVcX); NeurIPS 2024) and a safeguarding system ([WildGuard](https://proceedings.neurips.cc/paper_files/paper/2024/file/0f69b4b96a46f284b726fbd70f74fb3b-Paper-Datasets_and_Benchmarks_Track.pdf); NeurIPS 2024). I also study societal risks of human over-reliance on AI, measuring reliance behaviors ([RelAI](https://arxiv.org/pdf/2407.07950), NAACL 2025) and their impact on human creativity ([Artificial Hivemind](https://neurips.cc/virtual/2025/poster/121421); NeurIPS 2025).

My work has been featured in [QuantaMagazine](https://www.quantamagazine.org/chatbot-software-begins-to-face-fundamental-limitations-20250131/), [TechCrunch](https://techcrunch.com/2024/02/23/treating-a-chatbot-nicely-might-boost-its-performance-heres-why/?guccounter=1&guce_referrer=aHR0cHM6Ly90LmNvLw&guce_referrer_sig=AQAAAFGYVLMFUWxvSeJ-pBGGhl4EDBRfF7TxrTSPiA0whuo31NZWxQURPlMqxsbl5msyVt61-kx4EIhdK8GQiVeW6rhU1OVMWqqHX37fwFqn8X8wAuXCPGhd9SIslHAIeXVlefOWXdcsa4D34BnNp7lnvyuC-zP38xfZtJV1UhpE6PpV), [Science](https://www.science.org/content/article/ai-writing-improving-it-still-can-t-match-human-creativity), [LeMonde](https://www.lemonde.fr/pixels/article/2024/06/17/faut-il-s-inquieter-des-hallucinations-des-ia-comme-chatgpt-ou-gemini_6240971_4408996.html), [Science News](https://www.sciencenews.org/article/ai-understanding-reasoning-skill-assess), etc.

[//]: # (In the past, I earned my PhD from the **University of Alberta** and the [Alberta Machine Intelligence Institute]&#40;https://www.amii.ca/&#41; with [Osmar Zaiane]&#40;https://webdocs.cs.ualberta.ca/~zaiane/&#41;.)
I was fortunate to work with brilliant researchers in the field.
I have worked with <a href="https://sivareddy.in/">Siva Reddy</a> at **Mila/McGill**, 
with <a href="https://hrashkin.github.io/index.html">Hannah Rashkin</a>, 
<a href="https://tallinzen.net/research/">Tal Linzen</a>,
<a href="http://www.david-reitter.com/">David Reitter</a>,
<a href="https://cs.stanford.edu/~diyiy/">Diyi Yang</a>, and 
<a href="https://research.google/people/105075/">Tom Kwiatkowski</a> at **Google Research NYC** 
and have worked with <a href="https://www.microsoft.com/en-us/research/people/alsordon/">Alessandro Sordoni</a>, and 
[Goeff Gordon](https://www.cs.cmu.edu/~ggordon/) at **Microsoft Research Montreal**.

[//]: # (Link to your social media connections, too. This theme is set up to use [Font Awesome icons]&#40;http://fortawesome.github.io/Font-Awesome/&#41; and [Academicons]&#40;https://jpswalsh.github.io/academicons/&#41;, like the ones below. Add your Facebook, Twitter, LinkedIn, Google Scholar, or just disable all of them.)
